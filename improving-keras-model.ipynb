{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f85da4",
   "metadata": {},
   "source": [
    "# Improving your Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073024d",
   "metadata": {},
   "source": [
    "- Dataset: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5303f32",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3e070a-c30c-490a-a9bc-9923543d3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install keras -y\n",
    "# ! conda install tensorflow -y\n",
    "# ! conda install xlrd -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944c96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3284bef0-302a-451f-b0b3-b120cb524924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset from UCI ML Repository\n",
    "# ! curl -o default.xls https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a586285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = pd.read_excel('data/default.xls', header=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad685ab-2b46-4f69-acdd-f4dc206d838f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing data\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdbc6b7-b3c0-4545-b83b-2d4d1c496862",
   "metadata": {},
   "source": [
    "Split into input (X) and output (y) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcb0c799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# predictors include all variables but ID and default\n",
    "X = df.drop(['ID', 'default payment next month'], axis=1)\n",
    "# convert target to categorical\n",
    "y = to_categorical(df['default payment next month'])\n",
    "# note that the y-variable is now one-hot encoded\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ce3a8e-db62-4287-a2eb-c3e5affed60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d969217-aad4-4d06-8d39-487da3c8d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0bf8e",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "How many layers should the model contain?   \n",
    "* There's a mountain of commentary on the question of hidden layer configuration in NNs (see the insanely thorough and insightful NN FAQ for an excellent summary of that commentary). One issue within this subject on which there is a consensus is the performance difference from adding additional hidden layers: the situations in which performance improves with a second (or third, etc.) hidden layer are very few. **One hidden layer is sufficient for the large majority of problems.**\n",
    "* There are really two decisions that must be made regarding the hidden layers: how many hidden layers to actually have in the neural network and how many neurons will be in each of these layers. \n",
    "* Neural networks with two hidden layers can represent functions with any kind of shape. There is currently no theoretical reason to use neural networks with any more than two hidden layers.\n",
    " - [source](https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8380330-dc92-46fb-9dc5-670a49aa1a24",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea3001-b9bf-48c3-9127-7083f01a8a1a",
   "metadata": {},
   "source": [
    "The number of nodes in the input layer is always determined by number of predictors. The number of neurons comprising that layer is equal to the number of features (columns) in your data. Note: Some NN configurations add one additional node for a bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99113e8b-d816-456d-954f-80b6e06d2707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# number of nodes in the input layer \n",
    "nodes_input_layer = X_train.shape[1]\n",
    "print(nodes_input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe5242-3c80-4be8-bc53-393b48961c16",
   "metadata": {},
   "source": [
    "Like the Input layer, every NN has exactly one output layer. Determining its size (number of neurons) is simple; it is completely determined by the chosen model configuration.\n",
    "* If the NN is a regressor, then the output layer has a single node.\n",
    "\n",
    "* If the NN is a classifier, then it also has a single node unless softmax is used in which case the output layer has one node per class label in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad9f00-c8e2-4c7b-83d3-9c136c2ada0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of nodes in output layer\n",
    "nodes_output_layer = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2387d-56d8-40f6-840f-5f397e2ac918",
   "metadata": {},
   "source": [
    "The number of nodes in the hidden layers is not easy to determine. There is no universal answer for this question yet. Ultimately, the selection of an architecture for your neural network will come down to trial and error.\n",
    "* Using too few neurons in the hidden layers will result in underfitting\n",
    "* Too many neurons in the hidden layers may result in overfitting   \n",
    "\n",
    "There are many rule-of-thumb methods for determining the correct number of neurons to use in the hidden layers, such as the following:\n",
    "\n",
    "*    The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
    "*    The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
    "*    The number of hidden neurons should be less than twice the size of the input layer.\n",
    "\n",
    "- [source](https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw)\n",
    "* [further reading](https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0615082f-0d14-4ed6-9afd-ebdbdad47759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of nodes in first hidden layer\n",
    "nodes_hidden_layer = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316107fd-490e-4532-8d2d-9673d60e2832",
   "metadata": {},
   "source": [
    "Rules for the activation function\n",
    "\n",
    "Input and Output Layers:\n",
    "* The input layer does not require an activation function.\n",
    "* For regression problems, the output layer does not require an activation function.\n",
    "* For binary classification problems with a single output variable, the activation function should be \"sigmoid\".\n",
    "* For multi-label classification problems with a single output variable, the activation function should be \"softmax\".  \n",
    "\n",
    "Hidden Layers:\n",
    "* The rectified linear activation function, or ReLU activation function, is perhaps the most common function used for hidden layers.\n",
    "* Sigmoid and Tanh used to be popular but were more susceptible to vanishing gradients that prevent deep models from being trained\n",
    "* Recurrent networks still commonly use Tanh or sigmoid activation functions, or even both. \n",
    "\n",
    "\n",
    "Additional reading:\n",
    "* [Jason Brownlee](https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/)\n",
    "* [Keras documentation](https://keras.io/api/layers/activations/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007015fa-7d5d-47bb-8fad-13a9b7ed9b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function for the hidden layer\n",
    "activation_function_hidden_layer = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d3a31-0877-485c-997a-c8d4f2ea43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function for the output layer\n",
    "activation_function_output_layer = 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e8d9b8-131c-401b-a144-9dc4b11720d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "\n",
    "# add layers\n",
    "model.add(Dense(12, \n",
    "                activation=activation_function_hidden_layer, \n",
    "                input_shape = (nodes_input_layer,) # note: the final comma is important\n",
    "               )\n",
    "         )\n",
    "model.add(Dense(nodes_output_layer, \n",
    "                activation=activation_function_output_layer )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcee95b1-ff83-4974-b9e5-ed43b6dbc2c3",
   "metadata": {},
   "source": [
    "#### Compile the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93eff2d-af6c-4650-a001-ad283114d363",
   "metadata": {},
   "source": [
    "How should I choose a loss function?\n",
    "* Regression:\n",
    "* Binary Classification:\n",
    "* Multi-Class Classification:\n",
    "\n",
    "\n",
    "Further reading: \n",
    "* [Jason Brownlee](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)\n",
    "* [Keras Documentation](https://keras.io/api/losses/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433ed71-f853-4999-9da8-49be7bfefac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_function='categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa969d85-4e45-4b2b-8ef2-47dc08e1b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization algo\n",
    "optimization_algorithm='adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5294ad-e0d2-4f68-ba87-fa7cc90f402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics for evaluation during training\n",
    "list_of_metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf1cd9c-e0a3-490b-8b78-ca49b9049fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss=loss_function, \n",
    "              optimizer=optimization_algorithm, \n",
    "              metrics=list_of_metrics\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fff239-cd4c-427f-bb22-45895c04ad7c",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffdde2-7e78-4bf3-a7bb-5fc4c4a7e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many epochs?\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000be3-3451-4e06-81d3-8cd5c83895af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc9210-0e62-4412-8db7-9d632a8539b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "early_stopping_monitor = EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae3ce8-087b-46a0-a232-3be4e170f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "class_weight = {0:ratio, 1:1-ratio}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bad199-e864-4246-8ebe-59941e0bfc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          # validation_data=(X_test,y_test), \n",
    "          epochs=epochs, \n",
    "          # batch_size=batch_size,\n",
    "          # class_weight=class_weight,\n",
    "          # callbacks = [early_stopping_monitor]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e59a66-0807-4871-b597-76ba51c9ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make probability predictions with the model (they come in pairs)\n",
    "y_probs = model.predict(X_test)\n",
    "# make class predictions with the model\n",
    "y_preds = (y_probs > 0.5).astype(int)\n",
    "# Evaluate the model\n",
    "print(metrics.classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98f943-e982-4225-9e94-27775423fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a4740d-a036-4e23-a540-7e0a4df7a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions with the model\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b247c8-7877-455e-8d0a-eb7185edfa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f29f8-e413-434b-9af9-9612906e8ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
